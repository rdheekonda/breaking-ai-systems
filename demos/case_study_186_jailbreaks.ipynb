{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: 186 Jailbreaks in 137 Minutes\n",
    "\n",
    "This case study presents the results of a **large-scale automated red team assessment** against a frontier open-weight model. Using three distinct attack strategies — TAP, GOAT, and Crescendo — we executed 240 attacks across 8 harm categories and achieved an overall **78% Attack Success Rate**, uncovering 186 jailbreaks in just 137 minutes.\n",
    "\n",
    "The full implementation, dataset, and analysis are available on GitHub and in the accompanying blog post.\n",
    "\n",
    "> **Blog**: [186 Jailbreaks: Applying MLOps to AI Red Teaming](https://dreadnode.io/blog/186-jailbreaks-applying-mlops-to-ai-red-teaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Assessment Setup\n",
    "\n",
    "We assessed the safety of **Llama Maverick-17B-128E-Instruct**, a frontier open-weight multimodal model, using an AI Red Teaming Evaluation framework.\n",
    "\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| **Target model** | `groq/meta-llama/llama-4-maverick-17b-128e-instruct` |\n",
    "| **Attacker model** | Kimi-2 Instruct |\n",
    "| **Judge model** | Kimi-2 Instruct |\n",
    "| **Dataset** | 80 prompts across 8 harm categories |\n",
    "| **Harm categories** | Violence, misinformation, weapons, cybersecurity, self-harm, and others |\n",
    "| **Attack methods** | TAP, GOAT, Crescendo |\n",
    "| **Total attacks** | 240 (80 prompts x 3 methods) |\n",
    "| **Budget** | Max 200 trials per attack |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Attack Methods\n",
    "\n",
    "The three attack strategies each take a different approach to bypassing safety guardrails:\n",
    "\n",
    "### TAP (Tree of Attacks with Pruning)\n",
    "An attacker LLM generates a **tree of candidate jailbreak prompts**, evaluates each branch, prunes low-scoring paths, and expands promising ones. Best for discovering diverse attack vectors across the full attack surface.\n",
    "\n",
    "### GOAT (Graph of Attacks)\n",
    "Optimizes for **query efficiency** — finding successful jailbreaks with the fewest model interactions. Structures the attack as a graph traversal, reusing successful patterns. Best for stealth scenarios where minimizing interaction footprint is critical.\n",
    "\n",
    "### Crescendo\n",
    "A **multi-turn escalation strategy** that starts with benign-seeming requests and gradually increases the severity across conversation turns. Exploits the model's tendency to maintain conversational coherence. The most effective method in this assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Execution Summary\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| **Total attacks** | 240 |\n",
    "| **Successful jailbreaks** | 186 |\n",
    "| **Overall ASR** | ~78% |\n",
    "| **Total runtime** | ~137 minutes |\n",
    "| **Total queries** | 2,645 (avg ~11 queries/attack) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full AI Red Teaming Evaluation framework is available at:\n",
    "# https://github.com/dreadnode/sdk/blob/main/examples/airt/ai_red_teaming_eval.ipynb\n",
    "#\n",
    "# The framework orchestrates:\n",
    "# - TAP (Tree of Attacks with Pruning)\n",
    "# - GOAT (Graph of Attacks)\n",
    "# - Crescendo (gradual escalation)\n",
    "#\n",
    "# Across configurable datasets, models, and harm categories.\n",
    "\n",
    "print(\"Full implementation: https://github.com/dreadnode/sdk/blob/main/examples/airt/ai_red_teaming_eval.ipynb\")\n",
    "print()\n",
    "print(\"To run it locally:\")\n",
    "print(\"  git clone https://github.com/dreadnode/sdk.git\")\n",
    "print(\"  cd sdk/examples/airt\")\n",
    "print(\"  # Follow setup instructions in the notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Results by Attack Method\n",
    "\n",
    "| Attack | ASR | Avg Queries/Attack | Total Queries |\n",
    "|--------|-----|-------------------|---------------|\n",
    "| **Crescendo** | 97.5% | 19.0 | 1,523 |\n",
    "| **GOAT** | ~78% | ~7.0 | 530 |\n",
    "| **TAP** | ~57% | ~7.5 | 592 |\n",
    "| **Overall** | **~78%** | **~11** | **2,645** |\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- **Crescendo was the most effective attacker** with 97.5% ASR — its multi-turn escalation strategy consistently bypassed safety filters\n",
    "- **GOAT achieved high ASR with the lowest query footprint** — most efficient for stealth scenarios where minimizing interaction is critical\n",
    "- **TAP had moderate ASR but excels at finding diverse attack paths** — useful for comprehensive coverage of the attack surface\n",
    "- The combination of all three methods provides breadth (TAP), efficiency (GOAT), and depth (Crescendo) in attack coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Running Your Own Assessment\n",
    "\n",
    "Below is a minimal configuration skeleton showing how to set up and kick off a red team evaluation. The full execution logic is in the linked notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal configuration skeleton for running your own red team assessment.\n",
    "# The full execution logic is in the linked notebook.\n",
    "\n",
    "import os\n",
    "# os.environ[\"GROQ_API_KEY\"] = \"your-key\"\n",
    "\n",
    "# All models use LiteLLM routing — swap groq/ for any provider (openai/, anthropic/, azure/, etc.)\n",
    "config = {\n",
    "    \"dataset\": \"path/to/prompts.csv\",       # CSV with: goal, target, harm_category\n",
    "    \"num_prompts\": 80,                       # Prompts to evaluate\n",
    "    \"attacks\": [\"tap\", \"goat\", \"crescendo\"], # Attack methods\n",
    "    \"attacker_model\": \"groq/meta-llama/llama-4-maverick-17b-128e-instruct\",\n",
    "    \"target_model\": \"groq/meta-llama/llama-4-maverick-17b-128e-instruct\",\n",
    "    \"evaluator_model\": \"groq/meta-llama/llama-4-maverick-17b-128e-instruct\",\n",
    "    \"max_trials\": 200,                       # Max trials per attack\n",
    "    \"success_threshold\": 0.70,               # Score threshold for jailbreak\n",
    "}\n",
    "\n",
    "print(\"Configuration ready. See full notebook for execution:\")\n",
    "print(\"https://github.com/dreadnode/sdk/blob/main/examples/airt/ai_red_teaming_eval.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- **Blog**: [186 Jailbreaks: Applying MLOps to AI Red Teaming](https://dreadnode.io/blog/186-jailbreaks-applying-mlops-to-ai-red-teaming)\n",
    "- **Full Notebook**: [AI Red Teaming Eval](https://github.com/dreadnode/sdk/blob/main/examples/airt/ai_red_teaming_eval.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
