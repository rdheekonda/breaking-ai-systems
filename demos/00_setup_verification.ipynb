{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup & Verification\n",
    "\n",
    "Run this notebook to verify your environment is configured correctly before the demos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Verify Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  litellm              1.81.12\n",
      "  requests             2.32.5\n",
      "  numpy                2.4.2\n",
      "  matplotlib           3.10.8\n",
      "  pandas               3.0.0\n",
      "  rich                 14.3.2\n",
      "  torch                2.10.0\n",
      "  torchvision          0.25.0\n",
      "  Pillow               12.1.1\n",
      "\n",
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "import litellm\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import rich\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "for pkg in [\"litellm\", \"requests\", \"numpy\", \"matplotlib\", \"pandas\", \"rich\", \"torch\", \"torchvision\", \"Pillow\"]:\n",
    "    print(f\"  {pkg:20s} {version(pkg)}\")\n",
    "\n",
    "print(\"\\nAll imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify API Keys\n",
    "\n",
    "Your API keys should be in a `.env` file at the project root (see `README.md` → Setup → Step 4).\n",
    "\n",
    "| Key | Source | Used In |\n",
    "|-----|--------|--------|\n",
    "| `DREADNODE_API_KEY` | [platform.dreadnode.io](https://platform.dreadnode.io) | Demo 1 (Crucible challenge) |\n",
    "| `GROQ_API_KEY` | [console.groq.com](https://console.groq.com) | Demos 2, 3, Case Study (Llama 4 Maverick) |\n",
    "\n",
    "> **LiteLLM routing**: All LLM calls use [LiteLLM](https://docs.litellm.ai/) under the hood, so you can swap `groq/` for any supported provider (`openai/`, `anthropic/`, `azure/`, `bedrock/`, etc.) by changing the model string and setting the corresponding API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DREADNODE_API_KEY: configured (X6K...)\n",
      "  GROQ_API_KEY: configured (gsk...)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "for key in [\"DREADNODE_API_KEY\", \"GROQ_API_KEY\"]:\n",
    "    val = os.environ.get(key, \"\")\n",
    "    if val:\n",
    "        print(f\"  {key}: configured ({val[:3]}...)\")\n",
    "    else:\n",
    "        print(f\"  {key}: NOT SET \\u2014 add it to your .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Dreadnode Platform Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dreadnode Platform: connected\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\n",
    "    \"https://platform.dreadnode.io/api/challenges\",\n",
    "    headers={\"X-API-Key\": os.environ.get(\"DREADNODE_API_KEY\", \"\")},\n",
    "    timeout=10,\n",
    ")\n",
    "if response.status_code == 200:\n",
    "    print(\"  Dreadnode Platform: connected\")\n",
    "else:\n",
    "    print(f\"  Dreadnode Platform: connection failed (status {response.status_code})\")\n",
    "    print(\"  Check your DREADNODE_API_KEY in .env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test LLM API Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Groq API: connected (model: llama-4-maverick)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    resp = litellm.completion(\n",
    "        model=\"groq/meta-llama/llama-4-maverick-17b-128e-instruct\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Say 'hello' in one word.\"}],\n",
    "        max_tokens=10,\n",
    "    )\n",
    "    print(\"  Groq API: connected (model: llama-4-maverick)\")\n",
    "except Exception as e:\n",
    "    print(f\"  Groq API: failed \\u2014 {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Checklist\n",
    "\n",
    "- [ ] All packages imported successfully\n",
    "- [ ] `DREADNODE_API_KEY` configured\n",
    "- [ ] `GROQ_API_KEY` configured\n",
    "- [ ] Dreadnode Platform connection verified\n",
    "- [ ] Groq API access verified\n",
    "\n",
    "If all checks pass, you're ready for the demos!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "breaking-ai-systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
